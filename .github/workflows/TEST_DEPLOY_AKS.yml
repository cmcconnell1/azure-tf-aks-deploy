name: 'TEST_DEPLOY_AKS'

#on: [pull_request, workflow_dispatch]
on: [workflow_dispatch]

env:
  TF_LOG: INFO
  TF_VERSION: 1.2.6 ## Terraform version e.g: 1.1.0 Default=latest (Optional)
  TF_ENVIRONMENT: test ## this is a env var for the requisite terraform env and vars file
  TF_KEY: test-aks-cluster-tfstate ## AZ backend - Specifies name that will be given to terraform state file and plan artifact (Required)
  KEY_VAULT_NAME: testAksKeyVault2022

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: test    ## this sets the github project environment

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    # Set the working directory to main for the config files
    defaults:
      run:
        shell: bash
        working-directory: ./02_AKS_Cluster/environments/test/terraform

    env:
      # we should only have to change MY_ENV for each distinct environment
      ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
      ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
      ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
      ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}

      RESOURCE_GROUP: devtestdevops ## AZ backend - AZURE Resource Group hosting terraform backend storage acc (Required)
      STORAGE_ACCOUNT: devtestdevops29003 ## AZ backend - AZURE terraform backend storage acc (Required)
      CONTAINER_NAME: test-aks-cluster-tfstate ## AZ backend - AZURE storage container hosting state files (Required)

      AKS_CLUSTER_NAME: aks-testaksterraform
      AKS_CLUSTER_RESOURCE_GROUP: rg-testaksterraform

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v3

    # Install the preferred version of Terraform CLI
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: ${{ env.TF_VERSION }} 
        terraform_wrapper: true

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      id: init
      run: terraform init -backend-config="storage_account_name=$STORAGE_ACCOUNT" -backend-config="container_name=$CONTAINER_NAME" -backend-config="resource_group_name=$RESOURCE_GROUP" -backend-config="key=$TF_KEY"

    # Run a terraform plan for pull requests only
    - name: Terraform Plan
      id: plan
      #if: github.event_name == 'pull_request'
      #run: terraform plan -var-file=./${{ env.TF_ENVIRONMENT }}.tfvars -no-color
      run: terraform plan -var-file=./${{ env.TF_ENVIRONMENT }}.tfvars -no-color -var "ARM_CLIENT_ID=$ARM_CLIENT_ID" -var "ARM_CLIENT_SECRET=$ARM_CLIENT_SECRET" -var "ARM_TENANT_ID=$ARM_TENANT_ID" -var "ARM_SUBSCRIPTION_ID=$ARM_SUBSCRIPTION_ID"

      # On push to main, build or change infrastructure according to Terraform configuration files
    - name: Terraform Apply
      id: apply
      #if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      #run: terraform apply -var-file=./${{ env.TF_ENVIRONMENT }}.tfvars -auto-approve
      run: terraform apply -auto-approve -var-file=./${{ env.TF_ENVIRONMENT }}.tfvars  -var "ARM_CLIENT_ID=$ARM_CLIENT_ID" -var "ARM_CLIENT_SECRET=$ARM_CLIENT_SECRET" -var "ARM_TENANT_ID=$ARM_TENANT_ID" -var "ARM_SUBSCRIPTION_ID=$ARM_SUBSCRIPTION_ID"

      # continue with requisite infra configurations for AKS cluster
    - uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - uses: azure/setup-kubectl@v3.2

    - uses: azure/aks-set-context@v3
      with:
        cluster-name: ${{ env.AKS_CLUSTER_NAME }}
        resource-group: ${{ env.AKS_CLUSTER_RESOURCE_GROUP }}

    - name: Install ingress-nginx helm chart using script
      env:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
        CLUSTER_RESOURCE_GROUP_NAME: ${{ secrets.CLUSTER_RESOURCE_GROUP_NAME }}
        CLUSTER_NAME: ${{ secrets.CLUSTER_NAME }}
      run: |
        ./test-install-ingress-nginx-controller
      shell: bash
      working-directory: ./02_AKS_Cluster/environments/test/k8s/ingress-nginx

    # 2022-11-17 refactor for pod identity
    # this is terrible horrible hack but for now, we do not import the existing env-specific az keyvault into terraform.
    # we just need to grant the dynamic terraform managed pod identity application access to the pre-existing azure keyvault etc.
    # Note that if you import the resource then terraform owns it.
    # this is required for granting the access to the existing keyvaults to the SP that drives automation AND the SP for the dynamically created Pod ID SP--see below.
    - name: Update the non-terraform managed azure keyvault access policy for the dynamic aks-specific  pod identity etc. 
      env: 
          KEY_VAULT_NAME: ${{ env.KEY_VAULT_NAME }}
          ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
          ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
          ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
          AKS_CLUSTER_RESOURCE_GROUP: ${{ env.AKS_CLUSTER_RESOURCE_GROUP }}
      run: |
        # configure keyvault access for the SP "Application" i.e.: 'devtestdevops'
        az keyvault set-policy --name "$KEY_VAULT_NAME" --spn "$ARM_CLIENT_ID" --secret-permissions list get set
        az keyvault set-policy --name "$KEY_VAULT_NAME" --spn "$ARM_CLIENT_ID" --certificate-permissions list get listissuers
        az keyvault set-policy --name "$KEY_VAULT_NAME" --spn "$ARM_CLIENT_ID" --key-permissions list get verify 

        # configure keyvault access for the pod identity applications i.e.:  "id-testaksterraform-pod" SP 
        # this is truly nasty sheite but required since we cant manage access to env-specific keyvault within terraform since it doesnt own the resource
        # JIC that after terraform is executed and before our GHA workflows in dev-backend codebase run sadly we might have undesirable requirements here for the time being.
        # perhaps we could import the env-specific keyvaults into terraform for each distinct environment in another terraform module at some point.
        AKS_MANAGED_ID_PRINCIPAL_ID=$(az identity list -g $AKS_CLUSTER_RESOURCE_GROUP -o json | grep "principalId" | awk -F ":" '{print $2}' | sed 's/"//g; s/,//g') 
        az keyvault set-policy --name "$KEY_VAULT_NAME" --key-permissions get list recover --secret-permissions get list recover --certificate-permissions get list --object-id $AKS_MANAGED_ID_PRINCIPAL_ID
